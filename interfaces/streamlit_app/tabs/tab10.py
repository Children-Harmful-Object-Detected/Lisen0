import streamlit as st
import tempfile
import torch
from pathlib import Path
from ultralytics import YOLO
from interfaces.streamlit_app.modules.transformer import TransformerClassifier
from interfaces.streamlit_app.modules.info import analyze_video

def render_tab(MODEL_YOLO, MODEL_DIR: Path, RESULTS_DIR: Path):
    st.header("ğŸ’¡ ì§ì ‘ ì¶”ë¡  (íŒŒì¼ ì—…ë¡œë“œ)")
    st.info("ì´ íƒ­ì—ì„œ ë™ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´, ë¶„ì„ í›„ ê²°ê³¼ ì˜ìƒì´ ë°”ë¡œ ì•„ë˜ì— í‘œì‹œë©ë‹ˆë‹¤.")

    uploaded_file = st.file_uploader("ë¶„ì„í•  mp4 ì˜ìƒ ì—…ë¡œë“œ", type=["mp4"], key="direct_upload")

    if uploaded_file:
        # Save uploaded file to a temporary file
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmpfile:
            tmpfile.write(uploaded_file.getvalue())
            temp_video_path = tmpfile.name
        
        st.info(f"ì—…ë¡œë“œëœ íŒŒì¼: {uploaded_file.name}")

        start_clicked = st.button("ğŸš€ ë¶„ì„ ì‹œì‘", key="direct_start")
        
        if start_clicked:
            st.session_state.stop = False # Use the same session_state key `analyze_video` expects
            
            # Load models
            device = "cuda" if torch.cuda.is_available() else "cpu"
            yolo_pose = YOLO(str(MODEL_YOLO))
            yolo_box = YOLO(str(MODEL_YOLO))
            
            transformer_model_path = MODEL_DIR / "transformer_action_risk.pt"
            transformer = TransformerClassifier(input_dim=34, num_classes=3)
            transformer.load_state_dict(torch.load(transformer_model_path, map_location=device))
            transformer.to(device)
            transformer.eval()

            analyze_video(
                temp_video_path,
                yolo_pose,
                yolo_box,
                transformer,
                uploaded_file.name
            )
            
            name_stem = Path(uploaded_file.name).stem
            save_name = RESULTS_DIR / "preview" / f"preview_{name_stem}.mp4"

            if save_name.exists():
                st.success("ğŸ‰ ë¶„ì„ ì™„ë£Œ! ì•„ë˜ì—ì„œ ê²°ê³¼ ì˜ìƒì„ í™•ì¸í•˜ì„¸ìš”.")
                st.video(str(save_name))
            else:
                st.error("ì˜¤ë¥˜: ë¶„ì„ ê²°ê³¼ ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")
    st.subheader("ğŸ“· ì›¹ìº  ì‹¤ì‹œê°„ ë¶„ì„")

    try:
        from streamlit_webrtc import webrtc_streamer
        from interfaces.streamlit_app.modules.webcam_utils import VideoProcessor

        st.info("ì›¹ìº ì„ ì‹œì‘í•˜ë ¤ë©´ 'Start' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”. ë¶„ì„ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ í”„ë ˆì„ì— í‘œì‹œë©ë‹ˆë‹¤.")

        webrtc_streamer(
            key="webcam",
            video_processor_factory=lambda: VideoProcessor(MODEL_DIR),
            media_stream_constraints={"video": True, "audio": False},
            async_processing=True,
        )
    except ImportError:
        st.error("ì›¹ìº  ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'streamlit-webrtc' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        st.code("pip install streamlit-webrtc")
        st.warning("ìœ„ ëª…ë ¹ì–´ë¥¼ í„°ë¯¸ë„ì— ì…ë ¥í•˜ì—¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•œ í›„, ì•±ì„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
